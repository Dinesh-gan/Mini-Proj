{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7618623,"sourceType":"datasetVersion","datasetId":4437384},{"sourceId":7619418,"sourceType":"datasetVersion","datasetId":4437996},{"sourceId":8095810,"sourceType":"datasetVersion","datasetId":4780055}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport shutil\nimport PIL\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import DenseNet201 \nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.layers import Resizing, Rescaling, RandomFlip, RandomRotation\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.metrics import Recall\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-12T02:28:34.536914Z","iopub.execute_input":"2024-04-12T02:28:34.537238Z","iopub.status.idle":"2024-04-12T02:28:48.051910Z","shell.execute_reply.started":"2024-04-12T02:28:34.537215Z","shell.execute_reply":"2024-04-12T02:28:48.051080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv('/kaggle/input/bcn20000-metadata/bcn20000_metadata_2024-01-25.csv')\n# df = df[df['diagnosis'].isin(['melanoma', 'nevus'])]  # Include 'nevus' in addition to 'melanoma'\n\n# # Split the data into training, validation, and testing sets\n# train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n# validation_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n\n# # Define the source and root folders\n# source_folder = '/kaggle/input/bcn20000'\n# root_folder = '/kaggle/working/train-test-split'\n\n# # Create the necessary directories\n# os.makedirs(root_folder, exist_ok=True)\n# for subset in ['train', 'test', 'validation']:\n#     for diagnosis in ['melanoma', 'nevus']:\n#         os.makedirs(os.path.join(root_folder, subset, diagnosis), exist_ok=True)\n\n# # Define the function to copy images\n# def copy_images(df, subset):\n#     for index, row in df.iterrows():\n#         source_path = os.path.join(source_folder, row['isic_id'] + \".JPG\")  # Adjusted source path\n#         destination_path = os.path.join(root_folder, subset, row['diagnosis'], row['isic_id'] + \".JPG\")\n#         shutil.copy(source_path, destination_path)\n\n# # Copy the images\n# copy_images(train_df, 'train')\n# copy_images(validation_df, 'validation')\n# copy_images(test_df, 'test')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Train\")\n# print(\"Nevus:\",len(os.listdir(\"/kaggle/input/bcn20k/train-test-split/train/nevus\")))\n# print(\"Melanoma:\",len(os.listdir(\"/kaggle/input/bcn20k/train-test-split/train/melanoma\")))\n# print()\n\n# print(\"Test\")\n# print(\"Nevus:\",len(os.listdir(\"/kaggle/input/bcn20k/train-test-split/test/nevus\")))\n# print(\"Melanoma:\",len(os.listdir(\"/kaggle/input/bcn20k/train-test-split/test/melanoma\")))\n# print()\n\n# print(\"Validation\")\n# print(\"Nevus:\",len(os.listdir(\"/kaggle/input/bcn20k/train-test-split/validation/nevus\")))\n# print(\"Melanoma:\",len(os.listdir(\"/kaggle/input/bcn20k/train-test-split/validation/melanoma\")))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nimg_height = 180\nimg_width = 180\nchannels = 3","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:41:11.291143Z","iopub.execute_input":"2024-04-12T02:41:11.292356Z","iopub.status.idle":"2024-04-12T02:41:11.296660Z","shell.execute_reply.started":"2024-04-12T02:41:11.292321Z","shell.execute_reply":"2024-04-12T02:41:11.295635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    r'/kaggle/input/16xdataset/train-test-split/train',\n    shuffle=True,\n    image_size=(img_height, img_width),\n    batch_size=batch_size\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    r'/kaggle/input/16xdataset/train-test-split/validation',\n    shuffle=True,\n    image_size=(img_height, img_width),\n    batch_size=batch_size\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:41:14.611039Z","iopub.execute_input":"2024-04-12T02:41:14.611434Z","iopub.status.idle":"2024-04-12T02:41:20.957923Z","shell.execute_reply.started":"2024-04-12T02:41:14.611406Z","shell.execute_reply":"2024-04-12T02:41:20.957156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nn_classes = len(class_names)\n\nresize_and_rescale = Sequential([\n    Resizing(img_height, img_width),\n    Rescaling(1.0 / 255)\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:41:20.959593Z","iopub.execute_input":"2024-04-12T02:41:20.960025Z","iopub.status.idle":"2024-04-12T02:41:20.968764Z","shell.execute_reply.started":"2024-04-12T02:41:20.959993Z","shell.execute_reply":"2024-04-12T02:41:20.967771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(img_height, img_width, channels))  # Changed model\nbase_model.trainable = True  # Not training again\n\n\nmodel = Sequential([\n    resize_and_rescale,\n    base_model,\n    Flatten(),\n    Dense(1024, activation='relu'),\n    Dropout(0.5),\n    Dense(512, activation='relu'),\n    Dropout(0.5),\n    Dense(n_classes, activation='softmax')\n])\n\n\nmodel.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nepochs=150\ntrained = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:41:32.301110Z","iopub.execute_input":"2024-04-12T02:41:32.301984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained.history['accuracy']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained.history['val_accuracy']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset_path = r'/kaggle/input/16xdataset/train-test-split/test'\ntest_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    test_dataset_path,\n    shuffle=False,\n    image_size=(img_height, img_width),\n    batch_size=batch_size\n)\n\ntest_loss, test_accuracy = model.evaluate(test_ds)\n\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_true = []\nY_pred_classes = []\n\nfor images, labels in test_ds:\n    Y_pred = model.predict(images)\n    Y_pred_classes.extend(np.argmax(Y_pred, axis = 1))\n    Y_true.extend(labels.numpy())\n\n'''\nprint(\"result_inputs\")\nprint(\"Y_true:\", Y_true)\nprint(\"Y_pred_classes:\", Y_pred_classes)\n'''\n\nY_true = np.array(Y_true)\nY_pred_classes = np.array(Y_pred_classes)\n\nclassification_rep = classification_report(Y_true, Y_pred_classes, target_names=class_names)\nprint('Classification Report:')\nprint(classification_rep)\n\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nprint('Confusion Matrix:')\nsns.heatmap(confusion_mtx, annot=True, cbar = False, square = True, fmt = 'd', cmap = 'Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nmcc = matthews_corrcoef(Y_true, Y_pred_classes)\nprint('Matthews Correlation Coefficient:', mcc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# from PIL import Image\n\n# def upsample_image(image_path, new_width, new_height):\n#     with Image.open(image_path) as img:\n#         # Print the resolution of the original image\n#         print(f\"Original image resolution: {img.size}\")\n        \n#         # Display the original image\n#         plt.figure(figsize=(10, 5))\n#         plt.subplot(1, 2, 1)\n#         plt.imshow(img)\n#         plt.title('Original Image')\n        \n#         # Resize the image\n#         upsampled_img = img.resize((new_width, new_height), Image.BICUBIC)\n        \n#         # Print the resolution of the upsampled image\n#         print(f\"Upsampled image resolution: {upsampled_img.size}\")\n        \n#         # Display the upsampled image\n#         plt.subplot(1, 2, 2)\n#         plt.imshow(upsampled_img)\n#         plt.title('Upsampled Image')\n        \n#         return upsampled_img\n\n# # Upsample the image\n# upsampled_image = upsample_image(\"/kaggle/input/bcn20k/train-test-split/validation/melanoma/ISIC_0053660.JPG\", 1024, 1024)\n\n# # Show both images\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# upsampled_image = upsample_image(\"/kaggle/input/bcn20k/train-test-split/test/melanoma/ISIC_0053479.JPG\", 1024, 1024)\n# plt.imshow(upsampled_image)\n# plt.show()\n# upsampled_image.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}